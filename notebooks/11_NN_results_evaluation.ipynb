{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "from os import PathLike\n",
    "import seaborn as sns\n",
    "from kalman_reconstruction.custom_plot import (\n",
    "    set_custom_rcParams,\n",
    "    adjust_lightness,\n",
    "    plot_colors,\n",
    "    symmetrize_axis,\n",
    "    handler_map_alpha,\n",
    "    symmetrize_axis,\n",
    "    plot_state_with_probability,\n",
    ")\n",
    "from reconstruct_climate_indices.idealized_ocean import spunge_ocean, oscillatory_ocean\n",
    "from reconstruct_climate_indices.statistics import (\n",
    "    linear_regression_loglog,\n",
    "    power_density_spectrum,\n",
    "    xarray_dataset_welch,\n",
    "    xarray_dataarray_welch,\n",
    ")\n",
    "from kalman_reconstruction.pipeline import from_standard_dataset, all_choords_as_dim\n",
    "from kalman_reconstruction.statistics import normalize, crosscorr\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.figure import Figure\n",
    "\n",
    "# from sklearn.linear_model import LinearRegression\n",
    "from scipy import signal\n",
    "from typing import Dict\n",
    "import reconstruct_climate_indices.statistics as stati\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## LIGHT THEME\n",
    "# plt.style.use(\"seaborn-v0_8-whitegrid\")\n",
    "# dark_color = [0.3, 0.3, 0.3]\n",
    "# light_color = [0.8, 0.8, 0.8]\n",
    "# lightness_0 = 0.75\n",
    "# lightness_1 = 0.5\n",
    "# cmap = \"rocket\"\n",
    "# cmap_r = \"rocket_r\"\n",
    "\n",
    "### DARK THEME\n",
    "plt.style.use(\"dark_background\")\n",
    "dark_color = [0.7, 0.7, 0.7]\n",
    "light_color = [0.2, 0.2, 0.2]\n",
    "lightness_0 = 1.15\n",
    "lightness_1 = 1.5\n",
    "cmap = \"rocket_r\"\n",
    "cmap_r = \"rocket\"\n",
    "\n",
    "\n",
    "colors = set_custom_rcParams()\n",
    "plt.rcParams[\"grid.alpha\"] = 0.5\n",
    "plt.rcParams[\"axes.grid\"] = True\n",
    "\n",
    "plot_colors(colors)\n",
    "\n",
    "variables_color = dict()\n",
    "variables_color[\"SAT\"] = colors[0]\n",
    "variables_color[\"SST\"] = colors[2]\n",
    "variables_color[\"DOT\"] = colors[1]\n",
    "variables_color[\"latent\"] = colors[3]\n",
    "variables_color[\"loglikelihood\"] = colors[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REPO_PATH = Path(\".\").resolve().parent\n",
    "results_path = (\n",
    "    REPO_PATH / Path(\"results\") / \"Report\" / \"results\" / \"Evaluation_final_dark\"\n",
    ")\n",
    "results_path.mkdir(parents=True, exist_ok=True)\n",
    "SAVE_FIGURES = True\n",
    "\n",
    "\n",
    "def save_fig(fig: Figure, relative_path: PathLike, kwargs: Dict = dict()):\n",
    "    store_path = results_path / relative_path\n",
    "    store_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    if SAVE_FIGURES:\n",
    "        fig.savefig(store_path, **kwargs)\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To evaluate the performance of the Kalman-SEM sucess metrics were found:\n",
    "\n",
    "1. Increasing $\\mathcal{L}$ (sigmoid shape)\n",
    "2. Weak correlation of the final state of latent variable to Observations, $\\rho_{obs}\\approx 0$. If knowledge of hidden component exist, high correlation to it $|\\left| \\rho_{hid} \\right||\\approx 1$\n",
    "3. PSD of final state of the latent variable should be turning from white to red \\newline$m\\approx-2 to -4$\n",
    "\n",
    "The experiment used has the following properties:\n",
    "- Experiment_ID = ``750584923317940775``\n",
    "- ExperimentName = ``Evaluation-Idealized-Ocean``"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sponge ocean "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of runs : 30\n"
     ]
    }
   ],
   "source": [
    "run_names = [\n",
    "    \"polite-eel-349\",\n",
    "    \"flawless-loon-25\",\n",
    "    \"bustling-horse-699\",\n",
    "    \"grandiose-hawk-664\",\n",
    "]\n",
    "\n",
    "kalman_list = []\n",
    "input_list = []\n",
    "for name in run_names:\n",
    "    data_path = REPO_PATH / \"data\" / \"Evaluation-Idealized-Ocean\" / name\n",
    "    kalman_list.append(xr.open_dataset(data_path / (name + \"_kalman.nc\")))\n",
    "    input_list.append(xr.open_dataset(data_path / (name + \"_input.nc\")))\n",
    "sponge_kalman = xr.merge(kalman_list)\n",
    "sponge_input = xr.merge(input_list)\n",
    "\n",
    "\n",
    "# test = normalize(test, dim = \"time\", method = \"mean\")\n",
    "sponge_kalman_states = from_standard_dataset(ds=sponge_kalman)\n",
    "\n",
    "number_of_runs_sponge = len(sponge_kalman.seed)\n",
    "ocean_name_sponge = \"Sponge Ocean\"\n",
    "\n",
    "print(f\"number of runs : {number_of_runs_sponge}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oscillatory Ocean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of runs : 30\n"
     ]
    }
   ],
   "source": [
    "run_names = [\n",
    "    \"dapper-fox-131\",\n",
    "    \"respected-fowl-948\",\n",
    "    \"aged-bat-385\",\n",
    "    \"useful-mink-301\",\n",
    "    \"placid-vole-890\",\n",
    "    \"fun-ape-341\",\n",
    "]\n",
    "\n",
    "kalman_list = []\n",
    "input_list = []\n",
    "for name in run_names:\n",
    "    data_path = REPO_PATH / \"data\" / \"Evaluation-Idealized-Ocean\" / name\n",
    "    kalman_list.append(xr.open_dataset(data_path / (name + \"_kalman.nc\")))\n",
    "    input_list.append(xr.open_dataset(data_path / (name + \"_input.nc\")))\n",
    "oscillatory_kalman = xr.merge(kalman_list)\n",
    "oscillatory_input = xr.merge(input_list)\n",
    "\n",
    "\n",
    "# test = normalize(test, dim = \"time\", method = \"mean\")\n",
    "oscillatory_kalman_states = from_standard_dataset(ds=oscillatory_kalman)\n",
    "\n",
    "number_of_runs_oscillatory = len(oscillatory_kalman.seed)\n",
    "ocean_name_oscillatory = \"Oscillatory Ocean\"\n",
    "print(f\"number of runs : {number_of_runs_oscillatory}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check that seeds are the same:\n",
    "xr.testing.assert_equal(oscillatory_kalman.seed, sponge_kalman.seed)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation of loglikelihood and correlation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sponge Ocean"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the loglikelihoods of all experiments to estimate if all experiment succeed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=1, layout=\"constrained\")\n",
    "for t in sponge_kalman.tau0:\n",
    "    # for p in test.per0:\n",
    "    select_dict = dict(\n",
    "        tau0=t,\n",
    "        # per0 = p,\n",
    "    )\n",
    "    m = sponge_kalman.sel(select_dict)[\"log_likelihod\"].mean(dim=\"seed\")\n",
    "    s = sponge_kalman.sel(select_dict)[\"log_likelihod\"].std(dim=\"seed\")\n",
    "    plot_state_with_probability(\n",
    "        ax=ax,\n",
    "        x_value=sponge_kalman[\"kalman_itteration\"],\n",
    "        state=m,\n",
    "        prob=s,\n",
    "        stds=5,\n",
    "        line_kwargs=dict(color=variables_color[\"loglikelihood\"]),\n",
    "    )\n",
    "ax.set_xlabel(\"Itterations of Kalman-SEM\")\n",
    "ax.set_ylabel(\"Loglikelihood\")\n",
    "ax.set_title(\n",
    "    f\"Solid as mean and shaded as 2 std based on {number_of_runs_sponge} indep. runs for each parameter set\"\n",
    ")\n",
    "title = f\"Log likelihood evolution over kalman itterations.\"\n",
    "fig.suptitle(f\"{ocean_name_sponge} | {title}\")\n",
    "save_name = f\"Loglikelihood_evolution\"\n",
    "save_fig(fig=fig, relative_path=Path(ocean_name_sponge) / (save_name + \".svg\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loglikelihood increase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Loglikelihood increase\n",
    "sponge_kalman[\"log_likelihod_increase\"] = sponge_kalman[\"log_likelihod\"].isel(\n",
    "    kalman_itteration=-1\n",
    ") - sponge_kalman[\"log_likelihod\"].isel(kalman_itteration=0)\n",
    "da_lli = sponge_kalman[\"log_likelihod_increase\"]\n",
    "da_lli = da_lli.expand_dims(df=[0.115])\n",
    "# PLOT\n",
    "heatmap_kwargs = dict(\n",
    "    xticklabels=da_lli.tau0.values / 365.25,\n",
    "    yticklabels=da_lli.df.values,\n",
    "    square=True,\n",
    "    annot=True,\n",
    "    fmt=\".2f\",\n",
    "    vmin=-2.6,\n",
    "    vmax=0,\n",
    "    cmap=cmap,\n",
    ")\n",
    "\n",
    "m = da_lli.mean(dim=\"seed\") * 10 ** (-3)\n",
    "s = da_lli.std(dim=\"seed\") * 10 ** (-3)\n",
    "\n",
    "fig, axs = plt.subplots(nrows=2, ncols=1, layout=\"constrained\", figsize=(5, 3))\n",
    "sns.heatmap(m, ax=axs[0], **heatmap_kwargs)\n",
    "axs[0].set_title(rf\"Mean of {number_of_runs_sponge} indep. runs ($\\times 1000$)\")\n",
    "sns.heatmap(\n",
    "    -np.abs(s),\n",
    "    ax=axs[1],\n",
    "    **heatmap_kwargs,\n",
    ")\n",
    "axs[1].set_title(f\"Std. of {number_of_runs_sponge} indep. runs\")\n",
    "\n",
    "for ax in axs:\n",
    "    ax.set_xlabel(r\"$\\tau_0$ in y\")\n",
    "    ax.set_ylabel(r\"$df$ in y\")\n",
    "\n",
    "title = f\"Log likelihood increase over all kalman itterations.\"\n",
    "fig.suptitle(f\"{ocean_name_sponge} | {title}\")\n",
    "save_name = f\"Loglikelihood_increase\"\n",
    "save_fig(fig=fig, relative_path=Path(ocean_name_sponge) / (save_name + \".svg\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "calculate correlation to all input variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate all correaltions\n",
    "corr_list = []\n",
    "\n",
    "for var in sponge_input.data_vars:\n",
    "    temp = crosscorr(\n",
    "        ds1=sponge_kalman_states[\"latent\"],\n",
    "        ds2=sponge_input[var],\n",
    "        dim=\"time\",\n",
    "    )\n",
    "    temp.name = var\n",
    "    corr_list.append(temp)\n",
    "correlation_sponge = xr.merge(corr_list)\n",
    "correlation_sponge = correlation_sponge.expand_dims(df=[0.115])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plot correaltion to variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = \"SST\"\n",
    "da_corr = correlation_sponge[var]\n",
    "\n",
    "# PLOT\n",
    "\n",
    "heatmap_kwargs = dict(\n",
    "    xticklabels=da_corr.tau0.values / 365.25,\n",
    "    yticklabels=da_corr.df.values,\n",
    "    square=True,\n",
    "    annot=True,\n",
    "    fmt=\".2f\",\n",
    "    vmin=0,\n",
    "    vmax=1,\n",
    "    cmap=cmap_r,\n",
    ")\n",
    "\n",
    "m = np.abs(da_corr).mean(dim=\"seed\")\n",
    "s = np.abs(da_corr).std(dim=\"seed\")\n",
    "\n",
    "fig, axs = plt.subplots(nrows=2, ncols=1, layout=\"constrained\", figsize=(5, 3))\n",
    "# cbar_ax = fig.add_axes([.91, .3, .03, .4])\n",
    "sns.heatmap(m, ax=axs[0], **heatmap_kwargs)\n",
    "axs[0].set_title(rf\"Mean of {number_of_runs_sponge} indep. runs ($\\times 1000$)\")\n",
    "# sns.heatmap(s,\n",
    "#             ax = axs[1],\n",
    "#             **heatmap_kwargs\n",
    "#             )\n",
    "# axs[1].set_title(\"Std. of {number_of_runs_sponge} indep. runs\")\n",
    "sns.heatmap(\n",
    "    s,\n",
    "    ax=axs[1],\n",
    "    # cbar_ax=cbar_ax,\n",
    "    **heatmap_kwargs,\n",
    ")\n",
    "axs[1].set_title(f\"Std. of {number_of_runs_sponge} indep. runs\")\n",
    "\n",
    "for ax in axs:\n",
    "    ax.set_xlabel(r\"$\\tau_0$ in y\")\n",
    "    ax.set_ylabel(r\"$T_0 in y\")\n",
    "\n",
    "title = f\"Correlation Coefficient {var} to latent.\"\n",
    "fig.suptitle(f\"{ocean_name_sponge} | {title}\")\n",
    "save_name = f\"correlation_coefficient_{var}\"\n",
    "save_fig(fig=fig, relative_path=Path(ocean_name_sponge) / (save_name + \".svg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check correct order\n",
    "m"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oscillatory Ocean"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loglikelihoods of all experiments\n",
    "\n",
    "It is important to check if all experiments are saturated in the loglikelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=1, layout=\"constrained\")\n",
    "for t in oscillatory_kalman.tau0:\n",
    "    for p in oscillatory_kalman.per0:\n",
    "        select_dict = dict(\n",
    "            tau0=t,\n",
    "            per0=p,\n",
    "        )\n",
    "        m = oscillatory_kalman.sel(select_dict)[\"log_likelihod\"].mean(dim=\"seed\")\n",
    "        s = oscillatory_kalman.sel(select_dict)[\"log_likelihod\"].std(dim=\"seed\")\n",
    "        plot_state_with_probability(\n",
    "            ax=ax,\n",
    "            x_value=oscillatory_kalman[\"kalman_itteration\"],\n",
    "            state=m,\n",
    "            prob=s,\n",
    "            stds=2,\n",
    "            # line_kwargs=dict(color=variables_color[\"loglikelihood\"])\n",
    "        )\n",
    "ax.set_xlabel(\"Itterations of Kalman-SEM\")\n",
    "ax.set_ylabel(\"Loglikelihood\")\n",
    "ax.set_title(\n",
    "    f\"Solid as mean and shaded as 2 std based on {number_of_runs_sponge} indep. runs for each parameter set\"\n",
    ")\n",
    "\n",
    "title = f\"Log likelihood evolution over kalman itterations.\"\n",
    "fig.suptitle(f\"{ocean_name_oscillatory} | {title}\")\n",
    "save_name = f\"Loglikelihood_evolution\"\n",
    "save_fig(fig=fig, relative_path=Path(ocean_name_oscillatory) / (save_name + \".svg\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loglikelihood increase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Loglikelihood increase\n",
    "oscillatory_kalman[\"log_likelihod_increase\"] = oscillatory_kalman[\"log_likelihod\"].isel(\n",
    "    kalman_itteration=-1\n",
    ") - oscillatory_kalman[\"log_likelihod\"].isel(kalman_itteration=0)\n",
    "da_lli = oscillatory_kalman[\"log_likelihod_increase\"]\n",
    "\n",
    "# PLOT\n",
    "heatmap_kwargs = dict(\n",
    "    xticklabels=da_lli.per0.values / 365.25,\n",
    "    yticklabels=da_lli.tau0.values / 365.25,\n",
    "    square=True,\n",
    "    annot=True,\n",
    "    fmt=\".2f\",\n",
    "    vmin=0,\n",
    "    vmax=2.6,\n",
    "    cmap=cmap_r,\n",
    ")\n",
    "mean_heatmap_kwargs = heatmap_kwargs.copy()\n",
    "mean_heatmap_kwargs[\"cbar_kws\"] = dict(label=r\"Mean $\\mathcal{LI}$ in $10^3$\")\n",
    "std_heatmap_kwargs = heatmap_kwargs.copy()\n",
    "std_heatmap_kwargs[\"cbar_kws\"] = dict(label=r\"Std. $\\mathcal{LI}$ in $10^3$\")\n",
    "\n",
    "\n",
    "m = da_lli.mean(dim=\"seed\") * 10 ** (-3)\n",
    "s = da_lli.std(dim=\"seed\") * 10 ** (-3)\n",
    "\n",
    "# PLOT\n",
    "fig, axs = plt.subplots(\n",
    "    nrows=1, ncols=2, layout=\"constrained\", sharex=True, sharey=True, figsize=(8.5, 4)\n",
    ")\n",
    "\n",
    "sns.heatmap(m, ax=axs[0], **mean_heatmap_kwargs)\n",
    "\n",
    "axs[0].set_title(rf\"Mean of {number_of_runs_oscillatory} indep. runs\")\n",
    "sns.heatmap(\n",
    "    s,\n",
    "    ax=axs[1],\n",
    "    **std_heatmap_kwargs,\n",
    ")\n",
    "axs[1].set_title(f\"Std. of {number_of_runs_oscillatory} indep. runs\")\n",
    "\n",
    "for ax in axs:\n",
    "    ax.set_xlabel(r\"$T_0$ in y\")\n",
    "axs[0].set_ylabel(r\"$\\tau_0$ in y\")\n",
    "\n",
    "title = r\"Loglikelihood increase ($\\mathcal{LI}$)\"\n",
    "fig.suptitle(f\"{ocean_name_oscillatory} | {title}\")\n",
    "save_name = f\"Loglikelihood_increase\"\n",
    "save_fig(fig=fig, relative_path=Path(ocean_name_oscillatory) / (save_name + \".svg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(ncols=5, nrows=5, figsize=(10, 10), sharey=True, sharex=True)\n",
    "for i, t in enumerate(da_lli.tau0):\n",
    "    for j, p in enumerate(da_lli.per0):\n",
    "        sel_dict = dict(\n",
    "            tau0=t,\n",
    "            per0=p,\n",
    "        )\n",
    "        axs[i, j].hist(da_lli.sel(sel_dict), density=True, color=dark_color, alpha=0.2)\n",
    "        axs[i, j].axvline(\n",
    "            da_lli.mean(dim=\"seed\").sel(sel_dict), label=\"mean\", color=\"r\", linewidth=2\n",
    "        )\n",
    "        axs[i, j].axvline(\n",
    "            da_lli.median(dim=\"seed\").sel(sel_dict),\n",
    "            label=\"median\",\n",
    "            color=\"b\",\n",
    "            linewidth=2,\n",
    "        )\n",
    "        axs[i, j].set_title(\n",
    "            rf\"$\\tau_0$ = {da_lli.tau0[i].values / 365.25}\"\n",
    "            + \"\\n\"\n",
    "            + f\"$\\omega_0$ = {da_lli.per0[j].values / 365.25}\"\n",
    "        )\n",
    "        axs[i, j].legend()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlation to other variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate all correaltions\n",
    "corr_list = []\n",
    "\n",
    "for var in oscillatory_input.data_vars:\n",
    "    temp = crosscorr(\n",
    "        ds1=oscillatory_kalman_states[\"latent\"],\n",
    "        ds2=oscillatory_input[var],\n",
    "        dim=\"time\",\n",
    "    )\n",
    "    temp.name = var\n",
    "    corr_list.append(temp)\n",
    "correlation_oscillatory = xr.merge(corr_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = \"DOT\"\n",
    "da_corr = correlation_oscillatory[var]\n",
    "\n",
    "# PLOT\n",
    "\n",
    "heatmap_kwargs = dict(\n",
    "    xticklabels=da_corr.per0.values / 365.25,\n",
    "    yticklabels=da_corr.tau0.values / 365.25,\n",
    "    square=True,\n",
    "    annot=True,\n",
    "    fmt=\".2f\",\n",
    "    vmin=0,\n",
    "    vmax=1,\n",
    "    cmap=cmap_r,\n",
    ")\n",
    "\n",
    "mean_heatmap_kwargs = heatmap_kwargs.copy()\n",
    "mean_heatmap_kwargs[\"cbar_kws\"] = dict(label=r\"Mean $\\left| \\rho_{hid} \\right|$\")\n",
    "std_heatmap_kwargs = heatmap_kwargs.copy()\n",
    "std_heatmap_kwargs[\"cbar_kws\"] = dict(label=r\"Std. $\\left| \\rho_{hid} \\right|$\")\n",
    "\n",
    "\n",
    "m = np.abs(da_corr).mean(dim=\"seed\")\n",
    "s = np.abs(da_corr).std(dim=\"seed\")\n",
    "\n",
    "# PLOT\n",
    "fig, axs = plt.subplots(\n",
    "    nrows=1, ncols=2, layout=\"constrained\", sharex=True, sharey=True, figsize=(8.5, 4)\n",
    ")\n",
    "\n",
    "sns.heatmap(m, ax=axs[0], **mean_heatmap_kwargs)\n",
    "\n",
    "axs[0].set_title(rf\"Mean of {number_of_runs_oscillatory} indep. runs\")\n",
    "sns.heatmap(\n",
    "    s,\n",
    "    ax=axs[1],\n",
    "    **std_heatmap_kwargs,\n",
    ")\n",
    "axs[1].set_title(f\"Std. of {number_of_runs_oscillatory} indep. runs\")\n",
    "\n",
    "for ax in axs:\n",
    "    ax.set_xlabel(r\"$T_0$ in y\")\n",
    "axs[0].set_ylabel(r\"$\\tau_0$ in y\")\n",
    "\n",
    "\n",
    "title = f\"Correlation Coefficient {var} to latent \" + r\"($\\left| \\rho_{hid} \\right|$)\"\n",
    "fig.suptitle(f\"{ocean_name_oscillatory} | {title}\")\n",
    "save_name = f\"correlation_coefficient_{var}\"\n",
    "save_fig(fig=fig, relative_path=Path(ocean_name_oscillatory) / (save_name + \".svg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sponge_input.time[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validate that the axis are correct!\n",
      "tau0 = 5, per0 = 48\t 0.04\n",
      "tau0 = 20, per0 = 48\t 0.21\n",
      "tau0 = 15, per0 = 36\t 0.44\n"
     ]
    }
   ],
   "source": [
    "# Validate that the axis are correct:\n",
    "print(\"Validate that the axis are correct!\")\n",
    "for t, p in zip([5, 20, 15], [48, 48, 36]):\n",
    "    val = (\n",
    "        np.abs(correlation_oscillatory[var].sel(tau0=t * 365.25, per0=p * 365.25))\n",
    "        .mean(dim=\"seed\")\n",
    "        .values\n",
    "    )\n",
    "    print(f\"tau0 = {t}, per0 = {p}\\t {val:.2f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Power Spectral Density\n",
    "\n",
    "#### Compute the power spectral density\n",
    "\n",
    "NOTE: \n",
    "In order to compute a Power Spectral Density **WIHTOUT** using welch method, it is necessary to set the ``window = \"boxcar\"`` and ``npersep = \"lengt of the data\"``.\n",
    "```` python\n",
    "welch_kwargs = dict(\n",
    "    fs = 12,                    # period is 1/12 y -> fs = 12 y^{-1} \n",
    "    nperseg = len(data.time),   # length in timesteps\n",
    "    scaling = \"density\",\n",
    "    window = \"boxcar\"\n",
    ")\n",
    "````"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute PSD with frequency in year**{-1}\n",
    "# Set up welch_kwargs to use NO welch method.\n",
    "welch_kwargs = dict(\n",
    "    fs=12,  # period is 1/12 y -> fs = 12 y^{-1}\n",
    "    nperseg=len(sponge_input.time),  # length in timesteps\n",
    "    scaling=\"density\",\n",
    "    window=\"boxcar\",\n",
    ")\n",
    "\n",
    "psd_sponge = xarray_dataset_welch(sponge_input, dim=\"time\", welch_kwargs=welch_kwargs)\n",
    "psd_oscillatory = xarray_dataset_welch(\n",
    "    oscillatory_input, dim=\"time\", welch_kwargs=welch_kwargs\n",
    ")\n",
    "\n",
    "psd_sponge_kalman = xarray_dataset_welch(\n",
    "    sponge_kalman_states, dim=\"time\", welch_kwargs=welch_kwargs\n",
    ")\n",
    "psd_oscillatory_kalman = xarray_dataset_welch(\n",
    "    oscillatory_kalman_states, dim=\"time\", welch_kwargs=welch_kwargs\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perform ``linear_regression_loglog`` \n",
    "$f_{low} = 1/100$ in $y^{-1}$ for all!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F_LOW = 1 / 100\n",
    "F_HIGH = np.inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequencies_0, sponge_linear, sponge_regression = xr.apply_ufunc(\n",
    "    stati.linear_regression_loglog,\n",
    "    psd_sponge[\"frequency\"],  # Input frequencies\n",
    "    psd_sponge,  # Input spectrum\n",
    "    # psd_sponge[\"tau0\"] / 365.25,\n",
    "    input_core_dims=[[\"frequency\"], [\"frequency\"]],\n",
    "    output_core_dims=[[\"frequency\"], [\"frequency\"], []],\n",
    "    vectorize=True,\n",
    "    # dask='parallelized',\n",
    "    # exclude_dims=set((\"frequency\",)),\n",
    "    output_dtypes=[float, float, object],\n",
    "    kwargs=dict(\n",
    "        f_low=F_LOW,\n",
    "        f_high=F_HIGH,\n",
    "        weights=\"f_inverse\",\n",
    "    ),\n",
    ")\n",
    "\n",
    "frequencies_1, oscillatory_linear, oscillatory_regression = xr.apply_ufunc(\n",
    "    stati.linear_regression_loglog,\n",
    "    psd_oscillatory[\"frequency\"],  # Input frequencies\n",
    "    psd_oscillatory,  # Input spectrum\n",
    "    input_core_dims=[[\"frequency\"], [\"frequency\"]],\n",
    "    output_core_dims=[[\"frequency\"], [\"frequency\"], []],\n",
    "    vectorize=True,\n",
    "    # dask='parallelized',\n",
    "    # exclude_dims=set((\"frequency\",)),\n",
    "    output_dtypes=[float, float, object],\n",
    "    kwargs=dict(\n",
    "        f_low=F_LOW,\n",
    "        f_high=F_HIGH,\n",
    "        weights=\"f_inverse\",\n",
    "    ),\n",
    ")\n",
    "\n",
    "frequencies_2, sponge_kalman_linear, sponge_kalman_regression = xr.apply_ufunc(\n",
    "    stati.linear_regression_loglog,\n",
    "    psd_sponge_kalman[\"frequency\"],  # Input frequencies\n",
    "    psd_sponge_kalman,  # Input spectrum\n",
    "    input_core_dims=[[\"frequency\"], [\"frequency\"]],\n",
    "    output_core_dims=[[\"frequency\"], [\"frequency\"], []],\n",
    "    vectorize=True,\n",
    "    # dask='parallelized',\n",
    "    # exclude_dims=set((\"frequency\",)),\n",
    "    output_dtypes=[float, float, object],\n",
    "    kwargs=dict(\n",
    "        f_low=F_LOW,\n",
    "        f_high=F_HIGH,\n",
    "        weights=\"f_inverse\",\n",
    "    ),\n",
    ")\n",
    "\n",
    "(\n",
    "    frequencies_3,\n",
    "    oscillatory_kalman_linear,\n",
    "    oscillatory_kalman_regression,\n",
    ") = xr.apply_ufunc(\n",
    "    stati.linear_regression_loglog,\n",
    "    psd_oscillatory_kalman[\"frequency\"],  # Input frequencies\n",
    "    psd_oscillatory_kalman,  # Input spectrum\n",
    "    input_core_dims=[[\"frequency\"], [\"frequency\"]],\n",
    "    output_core_dims=[[\"frequency\"], [\"frequency\"], []],\n",
    "    vectorize=True,\n",
    "    # dask='parallelized',\n",
    "    # exclude_dims=set((\"frequency\",)),\n",
    "    output_dtypes=[float, float, object],\n",
    "    kwargs=dict(\n",
    "        f_low=F_LOW,\n",
    "        f_high=F_HIGH,\n",
    "        weights=\"f_inverse\",\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assert that all frequencies are the same\n",
    "l = [\n",
    "    frequencies_0[\"frequency\"],\n",
    "    frequencies_1[\"frequency\"],\n",
    "    frequencies_2[\"frequency\"],\n",
    "    frequencies_3[\"frequency\"],\n",
    "]\n",
    "for idx in np.arange(len(l) - 1):\n",
    "    xr.testing.assert_equal(l[idx], l[idx - 1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### extract the slopes using xr.apply_ufunc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_slope(x: LinearRegression) -> float:\n",
    "    \"\"\"resturns\"\"\"\n",
    "    return x.coef_[0][0]\n",
    "\n",
    "\n",
    "sponge_slopes = xr.apply_ufunc(\n",
    "    get_slope,\n",
    "    sponge_regression,  # Input frequencies\n",
    "    vectorize=True,\n",
    "    # dask='parallelized',\n",
    "    # exclude_dims=set((\"frequency\",)),\n",
    "    output_dtypes=[float],\n",
    ")\n",
    "\n",
    "oscillatory_slopes = xr.apply_ufunc(\n",
    "    get_slope,\n",
    "    oscillatory_regression,  # Input frequencies\n",
    "    vectorize=True,\n",
    "    # dask='parallelized',\n",
    "    # exclude_dims=set((\"frequency\",)),\n",
    "    output_dtypes=[float],\n",
    ")\n",
    "\n",
    "sponge_kalman_slopes = xr.apply_ufunc(\n",
    "    get_slope,\n",
    "    sponge_kalman_regression,  # Input frequencies\n",
    "    vectorize=True,\n",
    "    # dask='parallelized',\n",
    "    # exclude_dims=set((\"frequency\",)),\n",
    "    output_dtypes=[float],\n",
    ")\n",
    "oscillatory_kalman_slopes = xr.apply_ufunc(\n",
    "    get_slope,\n",
    "    oscillatory_kalman_regression,  # Input frequencies\n",
    "    vectorize=True,\n",
    "    # dask='parallelized',\n",
    "    # exclude_dims=set((\"frequency\",)),\n",
    "    output_dtypes=[float],\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### plot the slope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = \"latent\"\n",
    "da_slopes = sponge_kalman_slopes[var]\n",
    "\n",
    "fig, axs = plt.subplots(ncols=5, figsize=(8, 2), sharey=True)\n",
    "for idx in range(5):\n",
    "    axs[idx].hist(da_slopes.isel(tau0=idx), density=True, color=dark_color, alpha=0.2)\n",
    "    axs[idx].axvline(\n",
    "        da_slopes.mean(dim=\"seed\").isel(tau0=idx), label=\"mean\", color=\"r\", linewidth=2\n",
    "    )\n",
    "    axs[idx].axvline(\n",
    "        da_slopes.median(dim=\"seed\").isel(tau0=idx),\n",
    "        label=\"median\",\n",
    "        color=\"b\",\n",
    "        linewidth=2,\n",
    "    )\n",
    "    axs[idx].set_title(rf\"$\\tau_0$ = {da_slopes.tau0[idx].values / 365.25}\")\n",
    "    axs[idx].legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = \"latent\"\n",
    "da_slopes = sponge_kalman_slopes[var]\n",
    "da_slopes = da_slopes.expand_dims(df=[0.115])\n",
    "heatmap_kwargs = dict(\n",
    "    xticklabels=da_slopes.tau0.values / 365.25,\n",
    "    yticklabels=da_slopes.df.values,\n",
    "    square=True,\n",
    "    annot=True,\n",
    "    fmt=\".2f\",\n",
    "    vmin=-4,\n",
    "    vmax=0,\n",
    "    cmap=cmap,\n",
    ")\n",
    "\n",
    "# Calculate mean and std\n",
    "m = da_slopes.mean(dim=\"seed\")\n",
    "s = da_slopes.std(dim=\"seed\")\n",
    "\n",
    "fig, axs = plt.subplots(nrows=2, ncols=1, layout=\"constrained\", figsize=(5, 3))\n",
    "# cbar_ax = fig.add_axes([.91, .3, .03, .4])\n",
    "# plot mean\n",
    "sns.heatmap(m, ax=axs[0], **heatmap_kwargs)\n",
    "axs[0].set_title(rf\"Mean of {number_of_runs_sponge} indep. runs ($\\times 1000$)\")\n",
    "# plot standard deviation\n",
    "sns.heatmap(\n",
    "    -s,\n",
    "    ax=axs[1],\n",
    "    # cbar_ax=cbar_ax,\n",
    "    **heatmap_kwargs,\n",
    ")\n",
    "axs[1].set_title(f\"Std. of {number_of_runs_oscillatory} indep. runs\")\n",
    "\n",
    "for ax in axs:\n",
    "    ax.set_ylabel(r\"$\\tau_0$ in y\")\n",
    "    ax.set_xlabel(r\"$T_0$ in y\")\n",
    "\n",
    "title = f\"Slope of linear regression in loglog space for {var}.\"\n",
    "fig.suptitle(f\"{ocean_name_sponge} | {title}\")\n",
    "save_name = f\"slope_linear_regression_{var}\"\n",
    "save_fig(fig=fig, relative_path=Path(ocean_name_sponge) / (save_name + \".svg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = \"latent\"\n",
    "da_slopes = oscillatory_kalman_slopes[var]\n",
    "\n",
    "fig, axs = plt.subplots(\n",
    "    ncols=5, nrows=5, figsize=(10, 10), sharey=True, sharex=True, layout=\"constrained\"\n",
    ")\n",
    "for i, t in enumerate(da_slopes.tau0):\n",
    "    for j, p in enumerate(da_slopes.per0):\n",
    "        sel_dict = dict(\n",
    "            tau0=t,\n",
    "            per0=p,\n",
    "        )\n",
    "        axs[i, j].hist(\n",
    "            da_slopes.sel(sel_dict), density=True, color=dark_color, alpha=0.2\n",
    "        )\n",
    "        axs[i, j].axvline(\n",
    "            da_slopes.mean(dim=\"seed\").sel(sel_dict),\n",
    "            label=\"mean\",\n",
    "            color=\"r\",\n",
    "            linewidth=2,\n",
    "        )\n",
    "        axs[i, j].axvline(\n",
    "            da_slopes.median(dim=\"seed\").sel(sel_dict),\n",
    "            label=\"median\",\n",
    "            color=\"b\",\n",
    "            linewidth=2,\n",
    "        )\n",
    "        axs[i, j].set_title(\n",
    "            rf\"$\\tau_0$ = {da_slopes.tau0[i].values / 365.25}\"\n",
    "            + \"\\n\"\n",
    "            + f\"$\\omega_0$ = {da_slopes.per0[j].values / 365.25}\"\n",
    "        )\n",
    "        axs[i, j].legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = \"latent\"\n",
    "da_slopes = oscillatory_kalman_slopes[var]\n",
    "heatmap_kwargs = dict(\n",
    "    xticklabels=da_slopes.per0.values / 365.25,\n",
    "    yticklabels=da_slopes.tau0.values / 365.25,\n",
    "    square=True,\n",
    "    annot=True,\n",
    "    fmt=\".2f\",\n",
    "    vmin=-2.5,\n",
    "    vmax=0,\n",
    "    cmap=cmap,\n",
    ")\n",
    "\n",
    "mean_heatmap_kwargs = heatmap_kwargs.copy()\n",
    "mean_heatmap_kwargs[\"cbar_kws\"] = dict(label=r\"Mean $m_{lat}$\")\n",
    "std_heatmap_kwargs = heatmap_kwargs.copy()\n",
    "std_heatmap_kwargs[\"cbar_kws\"] = dict(label=r\"Std. $m_{lat}$\")\n",
    "\n",
    "# Calculate mean and std\n",
    "m = da_slopes.mean(dim=\"seed\")\n",
    "s = da_slopes.std(dim=\"seed\")\n",
    "\n",
    "# PLOT\n",
    "fig, axs = plt.subplots(\n",
    "    nrows=1, ncols=2, layout=\"constrained\", sharex=True, sharey=True, figsize=(8.5, 4)\n",
    ")\n",
    "# Plot mean\n",
    "sns.heatmap(\n",
    "    m,\n",
    "    ax=axs[0],\n",
    "    **mean_heatmap_kwargs,\n",
    ")\n",
    "axs[0].set_title(f\"Mean of {number_of_runs_oscillatory} indep. runs\")\n",
    "# Plot standard deviation\n",
    "hm = sns.heatmap(\n",
    "    -s,\n",
    "    ax=axs[1],\n",
    "    **std_heatmap_kwargs,\n",
    ")\n",
    "axs[1].set_title(f\"Std. of {number_of_runs_oscillatory} indep. runs\")\n",
    "\n",
    "for ax in axs:\n",
    "    ax.set_xlabel(r\"$T_0$ in y\")\n",
    "axs[0].set_ylabel(r\"$\\tau_0$ in y\")\n",
    "\n",
    "title = f\"m for final state of {var} variable \" + r\"($m_{lat}$)\"\n",
    "fig.suptitle(f\"{ocean_name_oscillatory} | {title}\")\n",
    "save_name = f\"slope_linear_regression_{var}\"\n",
    "save_fig(\n",
    "    fig=fig,\n",
    "    relative_path=Path(ocean_name_oscillatory)\n",
    "    / (save_name + f\"_{F_LOW:.2E}_{F_HIGH:.2E}.svg\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detailed insights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot PSD Spectra SST, DOT and latent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = psd_oscillatory_kalman.latent.median(dim=\"seed\")\n",
    "m_DOT = psd_oscillatory.DOT.mean(dim=\"seed\")\n",
    "m_SST = psd_oscillatory.SST.mean(dim=\"seed\")\n",
    "mini = psd_oscillatory_kalman.latent.quantile(0.1, dim=\"seed\")\n",
    "maxi = psd_oscillatory_kalman.latent.quantile(0.9, dim=\"seed\")\n",
    "fig, axs = plt.subplots(\n",
    "    nrows=5, ncols=5, layout=\"constrained\", sharex=True, sharey=True, figsize=(10, 10)\n",
    ")\n",
    "for i, t in enumerate(oscillatory_kalman.tau0):\n",
    "    for j, p in enumerate(oscillatory_kalman.per0):\n",
    "        select_dict = dict(\n",
    "            tau0=t,\n",
    "            per0=p,\n",
    "        )\n",
    "        for s in psd_oscillatory_kalman.seed:\n",
    "            axs[i, j].plot(\n",
    "                psd_oscillatory.frequency,\n",
    "                psd_oscillatory_kalman.latent.sel(select_dict).sel(seed=s),\n",
    "                linewidth=1,\n",
    "                alpha=0.01,\n",
    "                color=dark_color,\n",
    "            )\n",
    "        h = axs[i, j].plot(\n",
    "            psd_oscillatory.frequency,\n",
    "            m.sel(select_dict),\n",
    "            alpha=1,\n",
    "            linewidth=2,\n",
    "            color=variables_color[\"latent\"],\n",
    "        )\n",
    "        axs[i, j].fill_between(\n",
    "            x=psd_oscillatory.frequency,\n",
    "            y1=mini.sel(select_dict),\n",
    "            y2=maxi.sel(select_dict),\n",
    "            color=h[0].get_color(),\n",
    "            alpha=0.4,\n",
    "        )\n",
    "        h = axs[i, j].plot(\n",
    "            psd_oscillatory.frequency,\n",
    "            m_DOT.sel(select_dict),\n",
    "            alpha=0.75,\n",
    "            linewidth=2,\n",
    "            color=variables_color[\"DOT\"],\n",
    "        )\n",
    "        h = axs[i, j].plot(\n",
    "            psd_oscillatory.frequency,\n",
    "            m_SST.sel(select_dict),\n",
    "            alpha=0.75,\n",
    "            linewidth=2,\n",
    "            color=variables_color[\"SST\"],\n",
    "        )\n",
    "\n",
    "        # plot_state_with_probability(\n",
    "        #     ax= ax,\n",
    "        #     x_value= psd_oscillatory.frequency,\n",
    "        #     state= m.sel(select_dict),\n",
    "        #     prob = s.sel(select_dict),\n",
    "        # )\n",
    "\n",
    "for i, t in enumerate(oscillatory_kalman.tau0):\n",
    "    axs[i, 0].set_ylabel(rf\"$\\tau_0$ = {t.values / 365.25} y\")\n",
    "for j, p in enumerate(oscillatory_kalman.per0):\n",
    "    axs[-1, j].set_xlabel(rf\"$T_0$ = {p.values / 365.25} y\")\n",
    "\n",
    "\n",
    "for ax in axs.flatten():\n",
    "    ax.set_yscale(\"log\")\n",
    "    ax.set_xscale(\"log\")\n",
    "    ax.set_ylim(ymin=10 ** (-8))\n",
    "\n",
    "\n",
    "save_fig(fig, relative_path=\"ALL_FREQUENCIES.pdf\")\n",
    "save_fig(fig, relative_path=\"ALL_FREQUENCIES.png\")\n",
    "save_fig(fig, relative_path=\"ALL_FREQUENCIES.svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot lagged correaltion SST, DOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lagged_correlation_DOT_SST = []\n",
    "for lag in np.arange(0, 48 * 12, 6):\n",
    "    lagged_correlation_DOT_SST.append(\n",
    "        crosscorr(\n",
    "            ds1=oscillatory_input.DOT, ds2=oscillatory_input.SST, lag=lag, dim=\"time\"\n",
    "        )\n",
    "        .expand_dims(lag=[lag])\n",
    "        .rename(\"lagged_correlation_DOT_SST\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_lagged_correlation_DOT_SST = xr.merge(lagged_correlation_DOT_SST)\n",
    "da_lagged_correlation_DOT_SST = ds_lagged_correlation_DOT_SST[\n",
    "    \"lagged_correlation_DOT_SST\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_crosscorr = da_lagged_correlation_DOT_SST.mean(dim=\"seed\")\n",
    "std_crosscorr = da_lagged_correlation_DOT_SST.std(dim=\"seed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(\n",
    "    nrows=5, ncols=5, layout=\"constrained\", sharex=True, sharey=True, figsize=(10, 10)\n",
    ")\n",
    "for i, t in enumerate(oscillatory_kalman.tau0):\n",
    "    for j, p in enumerate(oscillatory_kalman.per0):\n",
    "        select_dict = dict(\n",
    "            tau0=t,\n",
    "            per0=p,\n",
    "        )\n",
    "        ax = axs[i, j]\n",
    "        # ax.errorbar(m_crosscorr.lag / 12, m_crosscorr.sel(select_dict), yerr=std_crosscorr.sel(select_dict), fmt='.')\n",
    "        for s in da_lagged_correlation_DOT_SST.seed:\n",
    "            ax.plot(\n",
    "                da_lagged_correlation_DOT_SST.lag / 12,\n",
    "                da_lagged_correlation_DOT_SST.sel(select_dict).sel(seed=s),\n",
    "                color=dark_color,\n",
    "                alpha=0.25,\n",
    "            )\n",
    "        plot_state_with_probability(\n",
    "            ax=ax,\n",
    "            x_value=m_crosscorr.lag / 12,\n",
    "            state=m_crosscorr.sel(select_dict),\n",
    "            prob=std_crosscorr.sel(select_dict),\n",
    "            line_kwargs=dict(marker=\"+\"),\n",
    "            stds=1,\n",
    "        )\n",
    "\n",
    "for i, t in enumerate(oscillatory_kalman.tau0):\n",
    "    axs[i, 0].set_ylabel(rf\"$\\tau_0$ = {t.values / 365.25} y\")\n",
    "for j, p in enumerate(oscillatory_kalman.per0):\n",
    "    axs[-1, j].set_xlabel(rf\"$T_0$ = {p.values / 365.25} y\")\n",
    "\n",
    "\n",
    "save_fig(fig, relative_path=\"LAGGED_CORRELATION_ALL_FREQUENCIES.pdf\")\n",
    "save_fig(fig, relative_path=\"LAGGED_CORRELATION_ALL_FREQUENCIES.png\")\n",
    "save_fig(fig, relative_path=\"LAGGED_CORRELATION_ALL_FREQUENCIES.svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot normalized Distributions SAT, SST, DOT and latent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_ds = normalize(oscillatory_input.copy(), method=\"norm\", dim=\"time\")\n",
    "dx = 0.5\n",
    "extent = 5\n",
    "bin_values = np.arange(-extent, extent, dx) + dx / 2\n",
    "x_values = (bin_values[:-1] + bin_values[1:]) / 2\n",
    "c, v = xr.apply_ufunc(\n",
    "    np.histogram,\n",
    "    current_ds,  # Input frequencies\n",
    "    input_core_dims=[\n",
    "        [\"time\"],\n",
    "    ],\n",
    "    output_core_dims=[\n",
    "        [\"count\"],\n",
    "        [\"edge\"],\n",
    "    ],\n",
    "    vectorize=True,\n",
    "    # dask='parallelized',\n",
    "    # exclude_dims=set((\"frequency\",)),\n",
    "    output_dtypes=[float, float],\n",
    "    kwargs=dict(bins=bin_values, density=True),\n",
    ")\n",
    "\n",
    "# current_ds_mean = current_ds.mean(dim = \"seed\")\n",
    "# current_ds_std = current_ds.std(dim = \"seed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = \"DOT\"\n",
    "count_median = c[var].median(dim=\"seed\")\n",
    "# count_mean = c[var].mean(dim = \"seed\")\n",
    "# count_std = c[var].std(dim = \"seed\")\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(\n",
    "    nrows=5, ncols=5, layout=\"constrained\", sharex=True, sharey=True, figsize=(10, 10)\n",
    ")\n",
    "for i, t in enumerate(current_ds.tau0):\n",
    "    for j, p in enumerate(current_ds.per0):\n",
    "        select_dict = dict(\n",
    "            tau0=t,\n",
    "            per0=p,\n",
    "        )\n",
    "        ax = axs[i, j]\n",
    "        # ax.errorbar(m_crosscorr.lag / 12, m_crosscorr.sel(select_dict), yerr=std_crosscorr.sel(select_dict), fmt='.')\n",
    "        for s in current_ds.seed:\n",
    "            ax.plot(\n",
    "                x_values,\n",
    "                c[var].sel(select_dict).sel(seed=s),\n",
    "                color=dark_color,\n",
    "                alpha=0.2,\n",
    "            )\n",
    "        ax.plot(\n",
    "            x_values,\n",
    "            count_median.sel(select_dict),\n",
    "            marker=\"+\",\n",
    "            color=variables_color[var],\n",
    "            alpha=1,\n",
    "            linewidth=2,\n",
    "        )\n",
    "        # plot_state_with_probability(\n",
    "        #     ax = ax,\n",
    "        #     x_value=x_values,\n",
    "        #     state=count_mean.sel(select_dict),\n",
    "        #     prob=count_std.sel(select_dict),\n",
    "        #     line_kwargs=dict(marker = \"+\", color = variables_color[var]),\n",
    "        #     stds=0.96,\n",
    "        # )\n",
    "\n",
    "for i, t in enumerate(oscillatory_kalman.tau0):\n",
    "    axs[i, 0].set_ylabel(rf\"$\\tau_0$ = {t.values / 365.25} y\")\n",
    "for j, p in enumerate(oscillatory_kalman.per0):\n",
    "    axs[-1, j].set_xlabel(rf\"$T_0$ = {p.values / 365.25} y\")\n",
    "\n",
    "\n",
    "# save_fig(fig, relative_path=f\"DISTRIBUTION_{var}_ALL_FREQUENCIES.pdf\")\n",
    "save_fig(fig, relative_path=f\"DISTRIBUTION_{var}_ALL_FREQUENCIES.png\")\n",
    "save_fig(fig, relative_path=f\"DISTRIBUTION_{var}_ALL_FREQUENCIES.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "climNum",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
