{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Track parameter Experiments\n",
    "\n",
    "With this file the parameter experiments can be tracked using mlflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from kalman_reconstruction import pipeline\n",
    "from kalman_reconstruction.custom_plot import (\n",
    "    set_custom_rcParams,\n",
    ")\n",
    "from reconstruct_climate_indices.idealized_ocean import AMO_oscillatory_ocean\n",
    "from tqdm import tqdm\n",
    "\n",
    "from mlflow import (\n",
    "    end_run,\n",
    "    log_artifact,\n",
    "    log_params,\n",
    "    set_tracking_uri,\n",
    "    start_run,\n",
    ")\n",
    "import yaml\n",
    "\n",
    "set_custom_rcParams()\n",
    "plt.rcParams[\"figure.figsize\"] = (8, 8)\n",
    "colors = plt.rcParams[\"axes.prop_cycle\"].by_key()[\"color\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SUBDATA_PATH = \"AMO_oscillator_parameter_experiments\"\n",
    "PATH_FIGURES = Path(\"../results/AMO_oscillator_parameter_experiments\")\n",
    "SAVE_FIGURES = True\n",
    "\n",
    "\n",
    "def save_fig(fig, relative_path, **kwargs):\n",
    "    store_path = PATH_FIGURES / relative_path\n",
    "    store_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    if SAVE_FIGURES:\n",
    "        fig.savefig(store_path, **kwargs)\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def product_dict(**kwargs):\n",
    "    keys = kwargs.keys()\n",
    "    for instance in itertools.product(*kwargs.values()):\n",
    "        yield dict(zip(keys, instance))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Kalman Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed for the randomnumber generator\n",
    "seed = 39266\n",
    "# Varaince of the randomly initialized latent variable\n",
    "random_variance = 1\n",
    "# itterations of the kalman SEM\n",
    "nb_iter_SEM = 30\n",
    "# observation variables\n",
    "observation_variables = [\"AMO\", \"NAO\", \"EAP\"]\n",
    "# state variables\n",
    "state_variables = [\"AMO\", \"NAO\", \"EAP\", \"latent\"]\n",
    "\n",
    "# create the dictonary that shall be used ot store the kalman_settings in the mlflow tracking\n",
    "kalman_settings = dict(\n",
    "    RandomNumberGeneratorSeed=seed,\n",
    "    RandomVariance=random_variance,\n",
    "    NumberKalmanIteration=nb_iter_SEM,\n",
    "    ObservartionVariables=observation_variables,\n",
    "    StateVariables=state_variables,\n",
    ")\n",
    "# positional args for the kalman_SEM algorithm\n",
    "func_args = dict()\n",
    "# key word args for the kalman_SEM algorithm\n",
    "func_kwargs = dict(\n",
    "    observation_variables=observation_variables,\n",
    "    state_variables=state_variables,\n",
    "    nb_iter_SEM=nb_iter_SEM,\n",
    ")\n",
    "\n",
    "# Random number generators used to create the latent varibale.\n",
    "rng1 = np.random.default_rng(seed=seed)\n",
    "# rng2 = np.random.default_rng(seed=seed + 1)\n",
    "# rng3 = np.random.default_rng(seed=seed + 2)\n",
    "# rng4 = np.random.default_rng(seed=seed + 3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Experiment settings\n",
    "\n",
    "The model used is the ``AMO_oscillatory_ocean``. The parameters ``dNAO`` and ``dEAP`` will be changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_settings = dict(\n",
    "    nt=1000,  # timesteps\n",
    "    dt=30,  # days\n",
    "    per0=24 * 365.25,  # days\n",
    "    tau0=10 * 365.25,  # days\n",
    "    dNAO=0.1,\n",
    "    dEAP=0.1,\n",
    "    cNAOvsEAP=0,\n",
    ")\n",
    "\n",
    "\n",
    "modified_arguments = [\"dNAO\", \"dEAP\"]\n",
    "factors = np.array([0.1, 0.5, 1, 5, 10])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the experiments:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create all datasets by running the model function ``AMO_oscillatory_ocean``.\n",
    "\n",
    "The results will be combined into a single Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:00<00:00, 53.79it/s]\n"
     ]
    }
   ],
   "source": [
    "# create all the experiment setups\n",
    "experiment_setups = dict()\n",
    "for key in modified_arguments:\n",
    "    experiment_setups[key] = np.round(default_settings[key] * factors, 5)\n",
    "\n",
    "# all experiment settings are made up by the all combinations of the experiment setups\n",
    "experiment_settings = list(product_dict(**experiment_setups))\n",
    "\n",
    "data_list = []\n",
    "setting = default_settings.copy()\n",
    "# we will not track each individual model run.\n",
    "for s in tqdm(experiment_settings):\n",
    "    # update the settings with the current set from the experiment settings.\n",
    "    setting.update(**s)\n",
    "    # integrate the model and store the output xr.Dataset\n",
    "    data = AMO_oscillatory_ocean(**setting)\n",
    "    data_list.append(data)\n",
    "# merge all output Dataset into a single Dataset\n",
    "experiments = xr.merge(data_list)\n",
    "experiments"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run the ``xarray_Kalman_SEM`` function from the ``pipeline`` library.\n",
    "\n",
    "The ``run_function_on_multiple_subdatasets`` function allows to run the input function on all ``subdatasets`` specified by the ``subdataset_selections``. In this case these selections are given by the ``experiment_settings``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 10/30 [00:04<00:07,  2.71it/s]"
     ]
    }
   ],
   "source": [
    "input_kalman = experiments.copy()\n",
    "pipeline.add_random_variable(\n",
    "    ds=input_kalman, var_name=\"latent\", random_generator=rng1, variance=random_variance\n",
    ")\n",
    "experiments_kalman = pipeline.run_function_on_multiple_subdatasets(\n",
    "    processing_function=pipeline.xarray_Kalman_SEM,\n",
    "    parent_dataset=input_kalman,\n",
    "    subdataset_selections=experiment_settings,\n",
    "    func_args=func_args,\n",
    "    func_kwargs=func_kwargs,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Track the experiment using ``mlflow``\n",
    "Using mlflow, the following information will be stored: \n",
    "- Dataset containing the results from the ``AMO_oscillatory_ocean`` for all experiment settings.\n",
    "- Dataset containing the results from the ``xarray_Kalman_SEM`` for all experiment settings.\n",
    "- Settings to create the different Model runs using (``AMO_oscillatory_ocean``).\n",
    "- Settings used by the ``xarray_Kalman_SEM``.\n",
    "\n",
    "Therefor multiple setting for mlflow will need to be set by the User:\n",
    "- ExperimentID : Corresponds to the experiment_id used by ``mlflow`` to set the ``set_tracking_uri``.\n",
    "- SubdataPath : Name of the directory in which to store the results. This will be a child of the ``data`` directory. \n",
    "- MlflowPath : Name of the directory in which the mlflow tracking uri shall be used.\n",
    "- NOTE: \n",
    "    - Make sure that the RepoPath is correct! \n",
    "    - Make sure that ExperimentID exists! "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The folder structure will be :\n",
    "\n",
    "**Folder structure**\n",
    "\n",
    "    └───RepoPath\n",
    "        └───data\n",
    "            └───SubdataPath\n",
    "                └───run_id\n",
    "                    │    run_id_input.nc\n",
    "                    │    run_id_kalman.nc\n",
    "                    │    run_id_kalman_settings.yml\n",
    "                    │    run_id_parameter_settings.yml\n",
    "Where ``run_id`` is e.g. *553cbd3bc6ce44028c8daad12647c306*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Niebaum\\Documents\\Repositories\\reconstruct-climate-indices\n"
     ]
    }
   ],
   "source": [
    "ExperimentID = 665803199114752138\n",
    "SubdataPath = \"parameter-experiments-storage\"\n",
    "MlflowPath = \"mlruns\"\n",
    "ThisPath = Path(\".\").resolve()\n",
    "RepoPath = ThisPath.parent\n",
    "print(RepoPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'default_settings' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# prepare the parameter_settings to indlude all arrays used in the experiment_setup\u001b[39;00m\n\u001b[0;32m      2\u001b[0m parameter_settings \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m()\n\u001b[1;32m----> 3\u001b[0m parameter_settings\u001b[39m.\u001b[39mupdate(default_settings)\n\u001b[0;32m      4\u001b[0m parameter_settings\u001b[39m.\u001b[39mupdate(experiment_setups)\n\u001b[0;32m      5\u001b[0m \u001b[39mfor\u001b[39;00m key \u001b[39min\u001b[39;00m parameter_settings:\n",
      "\u001b[1;31mNameError\u001b[0m: name 'default_settings' is not defined"
     ]
    }
   ],
   "source": [
    "# prepare the parameter_settings to indlude all arrays used in the experiment_setup\n",
    "parameter_settings = dict()\n",
    "parameter_settings.update(default_settings)\n",
    "parameter_settings.update(experiment_setups)\n",
    "for key in parameter_settings:\n",
    "    try:\n",
    "        parameter_settings[key] = parameter_settings[key].tolist()\n",
    "    except:\n",
    "        pass\n",
    "# set the tracking_uri\n",
    "set_tracking_uri(RepoPath / MlflowPath)\n",
    "with start_run(experiment_id=ExperimentID) as run:\n",
    "    # retrieve the run_id\n",
    "    run_id = run.info.run_id\n",
    "\n",
    "    # Create Paths to the corresponding directories names\n",
    "    DataPath = RepoPath / \"data\"\n",
    "    SubdataPath = DataPath / SubdataPath / f\"{run_id}\"\n",
    "    SubdataPath.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Create file names to store the  different settings\n",
    "    ParameterSettingsPath = SubdataPath / f\"{run_id}_parameter_settings.yml\"\n",
    "    KalmanSettingsPath = SubdataPath / f\"{run_id}_kalman_settings.yml\"\n",
    "    InputFile = SubdataPath / f\"{run_id}_input.nc\"\n",
    "    KalmanFile = SubdataPath / f\"{run_id}_kalman.nc\"\n",
    "\n",
    "    # log all settings and file locations.\n",
    "    log_params(kalman_settings)\n",
    "    log_params(parameter_settings)\n",
    "    log_params(\n",
    "        dict(\n",
    "            ParameterSettingsFile=ParameterSettingsPath.relative_to(\n",
    "                RepoPath\n",
    "            ).as_posix(),\n",
    "            KalmanSettingsFile=KalmanSettingsPath.relative_to(RepoPath).as_posix(),\n",
    "            InputFile=InputFile.relative_to(RepoPath).as_posix(),\n",
    "            KalmanFile=KalmanFile.relative_to(RepoPath).as_posix(),\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # ---- Save Files ----\n",
    "    experiments.to_netcdf(InputFile)\n",
    "    experiments_kalman.to_netcdf(KalmanFile)\n",
    "    with open(ParameterSettingsPath, \"w\") as yaml_file:\n",
    "        yaml.dump(parameter_settings, yaml_file, default_flow_style=False)\n",
    "    with open(KalmanSettingsPath, \"w\") as yaml_file:\n",
    "        yaml.dump(kalman_settings, yaml_file, default_flow_style=False)\n",
    "\n",
    "    # log artifact of the settings\n",
    "    log_artifact(ParameterSettingsPath.as_posix())\n",
    "    log_artifact(KalmanSettingsPath.as_posix())\n",
    "\n",
    "end_run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "climNum",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
